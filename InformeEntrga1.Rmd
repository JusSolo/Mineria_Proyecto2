---
title: "Informe Proyecto 2 entrega 1"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- - "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---
```{r, librerías, include=FALSE}
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
```


# git: https://github.com/JusSolo/Mineria_Proyecto2.git
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

datos <- read.csv('train.csv')
```

## Análisis exploratorio

### descripción de las variables:

- **SalePrice**: cuantitativa, el precio de venta de la propiedad 
- **MSSubClass**: cuantitativa, la clase de construcción
- MSZoning:  cualitativa, la clasificación general de zona
- **LotFrontage**: cuantitativa,   pies lineales de calle conectada a la propiedad
- **LotArea**: cuantitativa,   tamaño del lote en pies cuadrados
- Street: cualittiva,  tipo de acceso vial
- Alley: tipo de acceso por callejón
- LotShape: cualitativa, forma general de la propiedad
- LandContour: cualitativa, relieve de la propiedad
- Utilities: cualitativa, tipo de servicios públicos disponibles
- LotConfig: cualitativa, configuración del lote
- LandSlope: cualitativa, pendiente de la propiedad
- Neighborhood: cualitativa, ubicaciones físicas dentro de los límites de la ciudad de Ames
- Condition1:cualitativa, proximidad a la carretera principal o ferrocarril
- Condition2:cualitativa, proximidad a la carretera principal o ferrocarril (si hay un segundo presente)
- BldgType: cualitativa, tipo de vivienda
- HouseStyle:cualitativa, estilo de vivienda
- **OverallQual**: cuantitativa, calidad general de materiales y acabados
- **OverallCond**: cuantitativa, calificación general de la condición
- **YearBuilt**: cuantitativa, año de construcción original
- **YearRemodAdd**: cuantitativa, año de remodelación
- RoofStyle: cualitativa, tipo de techo
- RoofMatl: cualitativa, material del techo
- Exterior1st: cualitativa, revestimiento exterior de la casa
- Exterior2nd: cualitativa, revestimiento exterior de la casa (si se utiliza más de un material)
- MasVnrType: cualitativa, tipo de revestimiento de mampostería
- **MasVnrArea**: cuantitativa,  área del revestimiento de mampostería en pies cuadrados
- ExterQual: cualitativa, calidad del material exterior
- ExterCond: cualitativa, condición actual del material en el exterior
- Foundation: cualitativa, tipo de cimentación
- BsmtQual: cualitativa, altura del sótano
- BsmtCond: cualitativa,  condición general del sótano
- BsmtExposure: cualitativa,  paredes del sótano de salida directa o a nivel de jardín
- BsmtFinType1: cualitativa,  calidad del área terminada del sótano (tipo 1)
- **BsmtFinSF1**: cuantitativa,   pies cuadrados terminados, tipo 1
- BsmtFinType2: cualitativa,  calidad del área terminada del sótano (tipo 2, si está presente)
- **BsmtFinSF2**: cuantitativa,  pies cuadrados terminados, tipo 2
- **BsmtUnfSF**: cuantitativa,  pies cuadrados sin terminar del área del sótano
- **TotalBsmtSF**: cuantitativa,  total de pies cuadrados del área del sótano
- Heating: cualitativa,  tipo de calefacción
- HeatingQC: cualitativa,  calidad y condición de la calefacción
- CentralAir: cualitativa,  aire acondicionado central
- Electrical: cualitativa,  sistema eléctrico
- **X1stFlrSF**: cuantitativa,  pies cuadrados del primer piso
- **X2ndFlrSF**: cuantitativa,  pies cuadrados del segundo piso
- **LowQualFinSF**: cuantitativa,  pies cuadrados terminados de baja calidad (todas las plantas)
- **GrLivArea**: cuantitativa,  pies cuadrados de área habitable sobre el nivel del suelo
- **BsmtFullBath**: cuantitativa,  baños completos en el sótano
- **BsmtHalfBath**: cuantitativa,  medios baños en el sótano
- **FullBath**: cuantitativa,  baños completos sobre el nivel del suelo
- **HalfBath**: cuantitativa,  medios baños sobre el nivel del suelo
- **BedroomAbvGr**: cuantitativa,  número de dormitorios sobre el nivel del sótano
- **KitchenAbvGr**: cuantitativa,  número de cocinas
- KitchenQual: cualitativa, calidad de la cocina
- **TotRmsAbvGrd**: cuantitativa,  total de habitaciones sobre el nivel del suelo (no incluye baños)
- Functional: cualitativa, calificación de funcionalidad de la vivienda
- **Fireplaces**: cuantitativa,  número de chimeneas
- FireplaceQu: cualitativa, calidad de la chimenea
- GarageType: cualitativa, ubicación del garaje
- **GarageYrBlt**: cuantitativa,  año en que se construyó el garaje
- GarageFinish: cualitativa, acabado interior del garaje
- **GarageCars**: cuantitativa,  capacidad del garaje en número de autos
- **GarageArea**: cuantitativa,  tamaño del garaje en pies cuadrados
- GarageQual: cualitativa, calidad del garaje
- GarageCond: cualitativa, condición del garaje
- PavedDrive: cualitativa, acceso pavimentado
- **WoodDeckSF**: cuantitativa,  área de la terraza de madera en pies cuadrados
- **OpenPorchSF**: cuantitativa,  área del porche abierto en pies cuadrados
- **EnclosedPorch**: cuantitativa,  área del porche cerrado en pies cuadrados
- **X3SsnPorch**: cuantitativa,  área del porche de tres estaciones en pies cuadrados
- **ScreenPorch**: cuantitativa,  área del porche con malla en pies cuadrados
- **PoolArea**: cuantitativa,  área de la piscina en pies cuadrados
- PoolQC: cualitativa, calidad de la piscina
- Fence: cualitativa, calidad de la cerca
- MiscFeature: cualitativa, característica miscelánea no cubierta en otras categorías
- **MiscVal**: cuantitativa,  valor en dólares de la característica miscelánea
- **MoSold**: cuantitativa,  mes en que se vendió
- **YrSold**: cuantitativa,  año en que se vendió
- SaleType: cualitativa, tipo de venta
- **SaleCondition**: cuantitativa,  condición de la venta

### Estadisticas descriptivas

```{r, resumen de todo, echo=FALSE}
summary(datos)
```
### Variables numéricas 
```{r, separacion de datos numéricos,echo=FALSE}
vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

datosC <- datos %>%
  select(all_of(vars_cuantitativas))

```
#### Estadístias descriptivas:
```{r, resumen, echo=FALSE}
summary(datosC)
```
Podemos notar que la gran mayoría de variables tienen datos en todas las filas. Excepto para algunos casos que a continuación se explica como se llenaran los datos faltantes:

- LotFrontage: pies lineales de calle conectada a la propiedad, si hay un Na se va a considerar que la propiedad no tiene acceso directo a la calle (por ejemplo tiene derecho de paso con otra propiedad que si tiene acceso a la calle). por lo que tiene sentido remplazar los Na's por 0.
- MasVnrArea : por razon similar tiene sentido remplazar los Na's por 0
- GarageYrBlt : el año de construccion del garaje, en este caso el Na's tiene sentido porque si una casa no tiene garaje, este no tiene año de construccio. Pero para no eliminar las casas sin garaje se va a remplazar los Na's por la mediana de la comlumna por ser un estadístico mas robunsto que la media, es decir que no tienede a sesgar los datos. 

#### variables completadas
```{r, completacion de los Na s, echo=FALSE}
datosC$LotFrontage[is.na(datosC$LotFrontage)] <- 0
datosC$MasVnrArea[is.na(datosC$MasVnrArea)] <- 0
datosC$GarageYrBlt[is.na(datosC$GarageYrBlt)] <- median(datosC$GarageYrBlt, na.rm = TRUE)
summary(datosC[,c("LotFrontage","MasVnrArea","GarageYrBlt")])
```
Otra cosa que se puede notar al leer los resultados del summary es que algunas variables como MiscVal, teniendo una media de 43 y un tercer cuartil de 0.00 tienen probablemente muchos datos atípicos de gran valor que sesgan la media. Vamos a normalizar los datos para poder hacer diagramas de caja y bigotes de todas variables a la ves. Para analizar visualmente el summary.

### Analisis de grafica de caja y bigotes


```{r, caja y bigotes, echo=FALSE}


# Estandarización Z-score (centrar y dividir por la desviación estándar)
dn <- as.data.frame(lapply(datosC, function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}))

# Convertir a formato largo para ggplot
datos_largos <- dn %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

# Graficar los boxplots
ggplot(datos_largos, aes(x = Variable, y = Valor)) +
  geom_boxplot(fill = "lightblue", alpha = 0.7, outlier.color = "red") +
  theme_minimal() +
  coord_flip() +  # Rotar para mejor visualización
  labs(title = "Grafica de caja y bigotes", x = "Variable", y = "Valor Estandarizado")


```

De esta esta grafica podemos notar que hay variables demasiado dispersas que podrían no ser buenas para elaborar una regresion. Otras que tienen casi todos los valores nulos. Tomando en cuenta que son variables de casas, puede ser que mansiones o casas muy grandes tengan otra escala de valores. Puede ser una buena idea crear clusters, alguna funcion que le asigne un cluster a una casa dada y crear regresiones lineales diferentes para cada cluster. Otra opcion sería no tomar en cuenta esas variables, quitar los datos atipicos y crear un modelo que sea bueno prediciendo el valor de una propiedad "usual". Para calcular el valor de mansiones o similares puede que el modelo no vaya a ver bueno. Para indagar más en estas opciones se hara un analisis de correlacion y un clustering.  

### Prueba de normalidad en las variables cuantitativas
Tabla de resultados de la prueba de Shapiro-Wilk
```{r,normalidad,  echo=FALSE}
library(dplyr)
library(nortest) # Para otras pruebas de normalidad

# Función para aplicar el test de Shapiro-Wilk si la muestra es menor a 5000
normalidad_test <- function(x) {
  if (length(x) < 5000) {
    return(shapiro.test(x)$p.value)
  } else {
    return(ks.test(x, "pnorm", mean(x, na.rm = TRUE), sd(x, na.rm = TRUE))$p.value)
  }
}

# Aplicar el test de normalidad a todas las columnas numéricas
p_values <- sapply(dn, normalidad_test)

# Convertir a data frame
resultados_normalidad <- data.frame(Variable = names(p_values), P_Value = p_values)

# Mostrar resultados
print(resultados_normalidad)

```
Se puede constatar que todas las variables tienen $p-valor<0.001$, por lo que se puede concluir que ninguna de las variables sigue una distribución normal. Pero para un modelo de regresión lineal no hay un supuesto de normalidad en la distribución de las variables, esto no debería de ser un problema. 
Dicho usar k-medias para elaborar un clustering puede no ser la mejor opción. 

### Analisis de  correlacion 
Matriz de correlacion entre variables numericas 
```{r mariz de correlacion}

rcor<-cor(datosC)
det(rcor)

```
Notese que el determinante de la matriz de correlacion es:
-7.391762e-38 por lo que hay mulicolinealidad enre las varibales tomadas. 

```{r visualizacion con mapa de calor, echo=FALSE}
library(corrplot)

corrplot(rcor)

```
Con el mapa de calor se observa las varibales relacionadas positivamente, son:

Sale price con overallQuall, Year Built con GarageYrBlt, GarageCars con GarageArea GrLivArea con TotRmsAbvGrd, 1stFlrSF con TotalBsmtSF

No se observa correlaciones negativas que sean significativas.

Las variables predictorias son las siguente:
OverallQual que tiene relacion postiva al precio de venta..
GarageArea, pues el tamano es predictor obvio, mayor area mayor precio.
GarageArea, A mayor capacidad para varios carros, agrega valor la propiedad. 
Year Built Las casas nuevas teenden a ser mas caras.
TotalBsmtSF El espacio en el sotano puede aumentar el valor 



### Analisis de grupos 

```{r hopkins, echo=FALSE}
library(hopkins)
set.seed(123)
hopkins(datosC)

```
El valor estadistico de hopkins cercano a 1 indica que los datos estan altamente agrupados, por lo que vale la pena hacer agrupamiento. Para verificar, se presenta el metodo grafico. 

```{r VAT}
library(factoextra)
datos_dist<- dist(datosC)
fviz_dist(datos_dist, show_labels=F)

```
En el mapa de calor se observan patrones de distancia que sugieren que hay tendencia a tener agrupamiento, afirmado lo que indicaba el valor estadistico de hopkins.


```{r clustering jerarquico matriz distancia}
matriz<-dist(datosC)

```

```{r cluster jerarquico y dendograma, echo=FALSE}
hc<-hclust(datos_dist, method = "ward.D2")
plot(hc, cex=0.5, axes=FALSE )
rect.hclust(hc, k=3)

```



```{r cortar endograma}
gr<-cutree(hc, k=3)
datosC$gruposHc<-gr

```

```{r tamaño de los grupos}
table(datosC$gruposHc)
```

```{r, print 1}
print(table(datosC$gruposHc))
```
```{r, print 2}
by(datosC, datosC[, "gruposHc"], colMeans)
```
En el grupo 1: casas de precio medio, con calidad general buena y area habiable moderada.
En el grupo 2: Casas mas antiguas y menor precio, con menor calidad y area habitable pequeño .
En el grupo 3: casas mas nuevas y de mayor precio, con calidad mayor y area habitable grande y garage mas grande.

#### Veamos la silueta
```{r silueta,echo=FALSE}
library(cluster)
silhc<-silhouette(gr,matriz)
mean(silhc[,3])

```
Aun con valor 0.5330381 sugiriendo que la agrupacion es razonablemente bueno, hay buena cohesion y separacion razonable. 
```{r}
plot(silhc, cex.names=.4, col=1:3)
```
En la agrupacion 3 es el menos bien definido requeriendo un analisis mas detallado. 
La tabla de clustering resultante muestra las observaciones de cada agrupamiento 

```{r}
library(mclust)
mc<-Mclust(datosC, 3)
summary(mc)
```
# Modelos de regresion lineal
## Variable Respuesta:
La variable que se quiere predecir es el precio de las casasa, es decir (Sale Price). 
## Conjuntos de entrenamiento y prueba

Se usara para un 80% de los datos para entrenamiento y 20% para la prueba. Manteniendo la proporcion de observaciones de cada cluster. 


```{r}
library(caret)
#VAriable objetivo
y<- datosC$SalePrice
set.seed(123)
trainI<- createDataPartition(y, p=0.8, list=FALSE)
train<-datosC[trainI, ]
test<-datosC[-trainI, ]

cat("Conjunto de entrenamiento (cantidad de muestras:", nrow(train), ") \n ")
head(train)

cat("Conjunto de prueba (cantidad de muestras:", nrow(test), ") \n ")
head(test)


```
#  Modelo univariado de regresión
Primero elijamos la variable independiente para el modelos univariado, lo idóneo es elegir la variable con mayor correlación. A continuación se muestras las 5 variables con mayor correlación a SalePrice:
```{r, echo=FALSE}
cor_saleprice <- sort(rcor["SalePrice", ], decreasing = TRUE)

head(cor_saleprice, 5)

```
La variable que se utilizara para este primer modelo es OverallQual, pues es la que mayor correlacion con SalePrice tiene (sin ser SalePrice). 

```{r, fit modelo univariado}
modelo0 <- lm(SalePrice~. ,data = train[,c("SalePrice","OverallQual")])
summary(modelo0)

```
La ecuación de la regresión es: $SalePrice = -91015.7 + 44462.8 OverallQual$ , y el modelo explica en 64% de la varianza. 

```{r}

plot(train$OverallQual, train$SalePrice, 
     main = "Regresión lineal",
     xlab = "OverallQual", 
     ylab = "SalePrice",
     pch = 16, col = "blue")

# Agrega la línea de regresión ajustada
abline(modelo0, col = "red", lwd = 2)

# Agrega una leyenda
legend("topleft", legend = c("Datos", "Línea de Regresión"), 
       col = c("blue", "red"), pch = c(16, NA), lwd = c(NA, 2))

```


```{r}
plot(modelo0)
```

Se puede ver que la varianza no es constante,  En el gráfico q-q se observa que los residuos no parecen estar normalmente distribuidos. Este modelo lineal no parece ser muy bueno. 

```{r}
lillie.test(modelo0$residuals)
```
Los residuos tampoco se distribuyen de manera normal. En resumen este modelo lineal de una variable no es bueno. 

# Modelo con todas las variables

```{r, fit modelo todas las variables}
modelo1 <- lm(SalePrice~. ,data = train)
summary(modelo1)
```

Las variables significativas mostrando relacion con el precio de ventas, entran:
OverallQual:   mas calidad, mayor precio de venta
LotArea: mas area, mayor precio de venta
YearBuild: Entre mas nueva la vivienda mayor precio de venta
BsmtFinSF1: mayor pies cuadrados terminados de sotano mayor precio de venta
X1stFlrSF: mayor pies cuadrados terminados en los pisos  mayor precio de venta
BedroomAbvrGr: Mas cantidad de cuartos mayor precio de venta
KitchenAbvGRr: menor numero de cocinas mayor precio de venta
TotRms: Mas abitaciones mayor precio de venta
GarageCars: Mas espacio de garage mayor precio de venta
WoodDeckSF: Mayor cantidad de pies cuadrados de la cubierta de madera mayor precio de venta
ScreePorch: Mayor pies cuadrado de porche con mosquitero mayor precio de venta
PoolArea: mayor area de picina mayor precio de venta

```{r Residuos}
plot(modelo1)

```

La mayoria de puntos estan distribuidos aleatoriamente al rededor de cero, por lo que hay cierta heterocedasticiad, por dispersion de los residuales, sugiriendo que la dispersion de residuales aumenta ligeramene a medida que aumentan los valores ajustados. No respetando los supuestos de regresion lineal

```{r}
library(nortest)
library(dplyr)
lillie.test(modelo1$residuals)

```

El p-valor es menor a 0.5 por lo que se rechaza hipotesis nula, no hay distribucion normal. Se normaliza

```{r normalizando train y test}
train_normal <- as.data.frame(scale(train))
test_normal <- as.data.frame(scale(test))
```

```{r}
modelo1normalizado <- lm(SalePrice~. ,data = train_normal)
summary(modelo1normalizado)
plot(modelo1normalizado)
```
Notese que normalizando los datos no mejoro significativamente, por lo que se selecciona otros predictores.




# Regresion con variables significativas

Vamos a hacer un ultimo modelo seleccionando solo variables significativas y que no tengan correlacion entre ellas, 
```{r}
library(glmnet)

# Prepara las variables independientes (X) y la dependiente (y)
X <- model.matrix(SalePrice ~ . , data = train)[, -1]  # Matriz sin el intercepto
y <- train$SalePrice

set.seed(123)
modelo_lasso <- cv.glmnet(X, y, alpha = 1)  # alpha = 1 para Lasso

# Muestra el mejor lambda según validación cruzada
mejor_lambda <- modelo_lasso$lambda.min
cat("Mejor lambda:", mejor_lambda, "\n")

```

```{r}
coeficientes <- coef(modelo_lasso, s = "lambda.min")
variables_seleccionadas <- rownames(coeficientes)[coeficientes[, 1] != 0]
variables_seleccionadas <- variables_seleccionadas[-1]  # Excluye el intercepto

cat("Variables seleccionadas:", variables_seleccionadas, "\n")

```

```{r}
# Filtra las variables seleccionadas en el data frame
formula <- as.formula(paste("SalePrice ~", paste(variables_seleccionadas, collapse = "+")))
modelo2 <- lm(formula, data = train)
modelo2 <-step(modelo2, direction = "backward")

# Resumen del modelo2
summary(modelo2)

```

```{r}
plot(modelo2)
```

Este ultimo modelos aun tiene heterocedasticidad, no parece ser normal, tiene unos 3 puntos atípicos y esplic un 85% de la varianza. 


# Comparacion de los modelos

```{r}

AIC(modelo0)
AIC(modelo1)
AIC(modelo2)

```


Podemos notar que el AIC del primer modeo es e más alto. Pero entre el modelo1 y el modelo2 el AIC es parecido aunque el modelo2 tiene uno un poco más pequeño. Podemos concluir que el último modelo es el mejor. Dicho eso ningun modelo cumple con los supuestos para que un modelo lineal sea válido. Si analizamos las gráfica podemos notar que el modelo es bueno y cumple mejor los supuestos para los valores de enmedio. Hacer un modelo por clister podría volver validos los supuestos. 


```{r  BIC}

BIC(modelo0)
BIC(modelo1)
BIC(modelo2)


```Nótese que el valor mas bajo de BIC es del modelo 2, concluyendo que es el mejor, coincidiendo con AIC. 

Veamos que tan bueno es el modelo, para ello la grafica siguiente de valores reales y las predicciones para SalePrice.
```{r predicciones del mejor modelo}

pred_modelo2<-predict(modelo2, newdata = train)

#grafico
plot(test$SalePrice, col="blue", main = "predicion de Modelo 2 vs valores originales")
points(pred_modelo2, col="red")
legend("topright", legent =c("original", "prediccion"), colc("blue", "red"), pch=1, cex=0.8)


```

Los puntos azules representan los datos reales de SalePrice en el conjunto de prueba, los puntos rojos las prediciones segun el modelo 2 para SalePrice. Nótese que en general los puntos rojos, que son las predicciones siguen las tendencias de los puntos azules, valores reales. Indicando que el modelo capta las variaciones, aunque hay diferencia significativa entre la predicion y el valor real en algunos puntos. Por lo que el modelo tiene capacidad de captruara algunas tendencias pero tiene limitaciones.


















