---
title: "Informe Proyecto 2 entrega 3"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---



```{r, include=FALSE}
# Cargar librerías necesarias
library(randomForest)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
library(glmnet)
library(e1071)
library(Metrics)

# Cargar la base de datos
datos <- read.csv('train.csv')

# Definir variables cuantitativas
vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

# Imputar valores faltantes en variables específicas
datos <- datos %>%
  mutate(
    LotFrontage = ifelse(is.na(LotFrontage), 0, LotFrontage),
    MasVnrArea = ifelse(is.na(MasVnrArea), 0, MasVnrArea),
    GarageYrBlt = ifelse(is.na(GarageYrBlt), median(GarageYrBlt, na.rm = TRUE), GarageYrBlt)
  )

# Seleccionar solo variables cuantitativas
datosC <- datos[, vars_cuantitativas]
```




# git: https://github.com/JusSolo/Mineria_Proyecto2.git


# 1. Elabore un modelo de regresión usando bayes ingenuo (naive bayes), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las hojas anteriores para que los modelos sean comparables.

En esta ocasión como naive Bayes así lo permite se tomaran todas las variables incluso las culitativas. 



```{r, recuperacion de el training y test }
y<- datos$SalePrice
set.seed(123)
trainI<- createDataPartition(y, p=0.7, list=FALSE)

train<-datos[trainI, ]
test<-datos[-trainI, ]

trainC<-datosC[trainI, ]
testC<-datosC[-trainI, ]


```



```{r, Entrenar modelo Naïve Bayes}


modelo <- naiveBayes(SalePrice ~ ., data = train)



```






# 2. Analice los resultados del modelo de regresión usando bayes ingenuo. ¿Qué tan bien le fue prediciendo? Utilice las métricas correctas.
```{r, evalucion del desempeño del modelo, echo=FALSE}
# Predicciones para test
predTest <- predict(modelo, newdata = test)
predTest <- as.numeric(as.character(predTest))  # Convertir a numérico

# Calcular métricas para test
rmse_test <- rmse(test$SalePrice, predTest)
mae_test  <- mae(test$SalePrice, predTest)
rmsle_test <- sqrt(mean((log1p(test$SalePrice) - log1p(predTest))^2))

# Calcular R^2 para test
SST_test <- sum((test$SalePrice - mean(test$SalePrice))^2)  # Suma de cuadrados total
SSE_test <- sum((test$SalePrice - predTest)^2)              # Suma de cuadrados del error
r2_test <- 1 - (SSE_test / SST_test)  # Fórmula de R^2

# Mostrar resultados para test
cat("RMSE test:", rmse_test, "\n")
cat("MAE test:", mae_test, "\n")
cat("RMSLE test:", rmsle_test, "\n")
cat("R^2 test:", r2_test, "\n")

# --------------------------------------------------------

# Predicciones para train
predTrain <- predict(modelo, newdata = train)
predTrain <- as.numeric(as.character(predTrain))  # Convertir a numérico

# Calcular métricas para train
rmse_train <- rmse(train$SalePrice, predTrain)
mae_train  <- mae(train$SalePrice, predTrain)
rmsle_train <- sqrt(mean((log1p(train$SalePrice) - log1p(predTrain))^2))

# Calcular R^2 para train
SST_train <- sum((train$SalePrice - mean(train$SalePrice))^2)  # Suma de cuadrados total
SSE_train <- sum((train$SalePrice - predTrain)^2)              # Suma de cuadrados del error
r2_train <- 1 - (SSE_train / SST_train)  # Fórmula de R^2

# Mostrar resultados para train
cat("RMSE train:", rmse_train, "\n")
cat("MAE train:", mae_train, "\n")
cat("RMSLE train:", rmsle_train, "\n")
cat("R^2 train:", r2_train, "\n")

```
El $R^2$ es de 0.6699 no esta muy cercano a 1, pero tampoco es terrible. El RMSLE es de 0.25 lo que nos indica que el modelo tiene margen de mejora.  

# 3. Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las entregas pasadas. ¿Cuál funcionó mejor?



```{r, comparacion de modelos, echo=FALSE}
# Entrenar modelo Naïve Bayes
library(e1071)
library(glmnet)

# Entrenar modelo Naïve Bayes
modelo_bayes <- naiveBayes(SalePrice ~ ., data = train)

# Predicciones para test
pred_bayes <- predict(modelo, newdata = test)  
predBayes_numeric <- as.numeric(as.character(pred_bayes))  # Convertir factor a numérico

# Calcular métricas para Naïve Bayes
rmse_bayes <- rmse(test$SalePrice, predBayes_numeric)
mae_bayes  <- mae(test$SalePrice, predBayes_numeric)
r2_bayes   <- 1 - sum((test$SalePrice - predBayes_numeric)^2) / sum((test$SalePrice - mean(test$SalePrice))^2)

# Modelo de Regresión Lineal
X_train <- model.matrix(SalePrice ~ ., data = trainC)[, -1]  # Matriz sin el intercepto
X_test <- model.matrix(SalePrice ~ ., data = testC)[, -1]
y_train <- train$SalePrice
y_test <- testC$SalePrice

set.seed(123)
modelo_lasso <- cv.glmnet(X_train, y_train, alpha = 1)  # Regularización Lasso

# Predicción con Lasso
pred_lasso <- predict(modelo_lasso, s = "lambda.min", newx = X_test)

# Calcular métricas para modelo de regresión lineal regularizada
rmse_lasso <- rmse(y_test, pred_lasso)
mae_lasso  <- mae(y_test, pred_lasso)
r2_lasso   <- 1 - sum((y_test - pred_lasso)^2) / sum((y_test - mean(y_test))^2)

# Modelo de árbol de decisión
arbol <- rpart(SalePrice ~ ., data = trainC)

# Predicción para test
pred_arbol <- predict(arbol, newdata = testC)

# Calcular métricas para árbol de decisión
rmse_arbol <- rmse(y_test, pred_arbol)
mae_arbol  <- mae(y_test, pred_arbol)
r2_arbol   <- 1 - sum((y_test - pred_arbol)^2) / sum((y_test - mean(y_test))^2)

# Comparación de modelos
resultados <- data.frame(
  Modelo = c("Naïve Bayes", "Regresión Lineal ", "Árbol de Regresión"),
  RMSE = c(rmse_bayes, rmse_lasso, rmse_arbol),
  MAE  = c(mae_bayes, mae_lasso, mae_arbol),
  R2   = c(r2_bayes, r2_lasso, r2_arbol)
)

# Mostrar resultados comparativos
print(resultados)

```

En la tabla comparativa con cualquiera de las tres métricas se puede concluir que el mejor modelo es el lineal, el segundo mejor es el  Naive Bayes  y el peor es el árbol de regresión. 


# 4. Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta.
```{r recuperacion de variable categorica}

train$precio_categoria<-cut(train$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)

test$precio_categoria<-cut(test$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)


#modelo NB para clasificacion

modeloClas<-naiveBayes(precio_categoria~.- SalePrice, data=train)


```




# 5. Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar.
```{r}
#prediccion del modelo
pred_nb_clas<-predict(modeloClas, newdata=test[, !names(test) %in% c("salePrice", "PriceCateoria") ])
                              


```


# 6. Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.

```{r}
#evualuar modelo
confusionMatrix(pred_nb_clas, test$precio_categoria)
```

Según la matriz de confusion, el moodelo mosto una efectividad en las categorias económicas y lujo con 109 y 9 predicciones correctas, respectivamente. Con efectviad moderada es el modelo es la categoria cara con 84 predicicones correctas. La categoria con menor efectividad es la de intermedio. 

Con lo que el modelo en general cuenta con precision del 59.86%,valor de Accuracy, por lo que se puede conciderar un rendimiento moderado. Con Kapa de 0.4545 que es la concordancia entre el valor real y el valor de prediccion. 

Por estadistica por clase el  modelo identifica correctamente todas las casas económicas, asi como las casas de lujo, segida de la categoria Cara que identifico en parte mayoría las casas caras y por último la categoria intermedia, que fue la que tuvo menos aciertos en clasificar las casas intermedias 

#7. Analice el modelo. ¿Cree que pueda estar sobreajustado?

```{r prediccion de modelo}
#evualuar modelo
pred_nb_train<-predict(modeloClas, newdata=train[, !names(train) %in% c("salePrice", "PriceCateoria") ])
                  
confusionMatrix(pred_nb_train, train$precio_categoria)
confusionMatrix(pred_nb_clas, test$precio_categoria)

```
El modelo de clasificacion Naive Bayes no se muestra signos significativos de sobreajuste. La presicion y el valor de Kappa son similares en los conjuntos de test y prueba, Ademas de que muestra dificultades similares al clasificar las categorias cara e intermedias, por lo que el modelo tiene rendimiento moderado y sin sobreajuste

#8. Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor?







```{r, eliminar Na, echo=FALSE}
# Cargar la base de datos
datos <- read.csv('train.csv')

# Función para obtener la moda (para variables categóricas)
get_mode <- function(x) {
  ux <- unique(na.omit(x))
  if (length(ux) == 0) return(NA)
  ux[which.max(tabulate(match(x, ux)))]
}

# Imputar numéricos con mediana y categóricas con moda
datos <- datos %>%
  mutate(
    # Imputar numéricos
    across(where(is.numeric), 
           ~ ifelse(is.na(.x), median(.x, na.rm = TRUE), .x)),
    # Imputar categóricos (factores o character)
    across(where(~ is.factor(.x) || is.character(.x)), 
           ~ {
             if (any(is.na(.x))) {
               if (is.factor(.x)) {
                 # Para factores, añadir nivel "Missing"
                 levels(.x) <- c(levels(.x), "Missing")
                 replace(.x, is.na(.x), "Missing")
               } else {
                 replace(.x, is.na(.x), get_mode(.x))
               }
             } else {
               .x
             }
           })
  )

# Eliminar columnas donde todos los valores son NA (por si acaso)
datos <- datos %>% select_if(~ !all(is.na(.x)))


# Verificar NAs restantes
cat("NAs después de imputación:", sum(is.na(datos)))

y <- datos$SalePrice
set.seed(123)
trainI <- createDataPartition(y, p=0.7, list=FALSE)
train <- datos[trainI, ]
test <- datos[-trainI, ]

# Crear variable categorica (sin NAs)
train$precio_categoria <- cut(train$SalePrice, 
                             breaks = c(0, 129975, 214000, 400000, Inf),
                             labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                             include.lowest = TRUE)
test$precio_categoria <- cut(test$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)
```

```{r validacion cruzada}


```




Ambos modelos tienen rendimiento menor que el 30% por lo que no necesariamente Naive Bayes el mas adecuado para este problema para la clasificacion. La validacion cruzada no mejoró el rendimiento. 

#9. Tanto para los modelos de regresión como de clasificación, pruebe con varios valores de los hiperparámetros, use el mejor modelo del tuneo, ¿Mejoraron los modelos? Explique
```{r}

```


#10. Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?








































