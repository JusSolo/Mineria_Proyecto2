---
title: "Informe Proyecto 2 entrega 4"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---

https://github.com/JusSolo/Mineria_Proyecto2.git 


```{r, include=FALSE}
# Cargar librerías necesarias
library(randomForest)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
library(glmnet)
library(e1071)
library(Metrics)
library(tidyverse)
library(class)



# Cargar la base de datos
datos <- read.csv('train.csv')

# Definir variables cuantitativas
vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

# Imputar valores faltantes en variables específicas
datos <- datos %>%
  mutate(
    LotFrontage = ifelse(is.na(LotFrontage), 0, LotFrontage),
    MasVnrArea = ifelse(is.na(MasVnrArea), 0, MasVnrArea),
    GarageYrBlt = ifelse(is.na(GarageYrBlt), median(GarageYrBlt, na.rm = TRUE), GarageYrBlt)
  )

# Seleccionar solo variables cuantitativas
datosC <- datos[, vars_cuantitativas]
```




# git: https://github.com/JusSolo/Mineria_Proyecto2.git


# 1. Elabore un modelo de regresión usando K nearest Neighbors (KNN), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las entregas anteriores para que los modelos sean comparables.

```{r, regresion usando KNN}
y<- datos$SalePrice
set.seed(123)
trainI<- createDataPartition(y, p=0.7, list=FALSE)

train<-datosC[trainI, ]
test<-datosC[-trainI, ]

## Modelo:
train<-train[complete.cases(train),]
k_vecinos <- round(sqrt(nrow(datosC)),0)
parametros <- expand.grid(k = k_vecinos)

modelo_knn1 <- train(
  SalePrice~., 
  data=train, 
  method = "knn", 
  preProcess= c("center","scale","knnImpute"),
  tuneGrid = parametros
)
predModelo1 <- predict(modelo_knn1, newdata=test)


```


# 2. Analice los resultados del modelo de regresión usando KNN. ¿Qué tan bien le fue prediciendo? Utilice las métricas correctas.

```{r}

pred_test <- predict(modelo_knn1, newdata = test)

metrics <- postResample(pred_test, test$SalePrice)
print(metrics)

```
 El $R^2= 0.784$ es aceptable, El MAE es del orden de los $20,000 lo que para el precio de una casa parece aceptable. 


# 3. Compare los resultados con el modelo de regresión lineal, el mejor modelo de árbol de regresión y de naive bayes que hizo en las entregas pasadas. ¿Cuál funcionó mejor?

```{r, modelos anteriores, echo=FALSE}
modelo_lineal <- train(
  SalePrice ~ ., 
  data = train, 
  method = "lm",  # Método para regresión lineal
  preProcess = c("center", "scale", "knnImpute")  # Preprocesamiento igual al de KNN
)


arbol <- rpart(SalePrice~.,data = train)


modelo_naivbayes <- naiveBayes(SalePrice ~ ., data = train)

# Predicciones en test para cada modelo
pred_knn <- predict(modelo_knn1, newdata = test)
pred_arbol <- predict(arbol, newdata = test)
pred_lineal <- predict(modelo_lineal, newdata = test)
pred_naivbayes <- as.numeric(predict(modelo_naivbayes, newdata = test))

# Función para calcular métricas con caret
calcular_metricas <- function(y_real, y_pred) {
  resultados <- postResample(y_pred, y_real)  # Devuelve RMSE, R², MAE
  data.frame(
    RMSE = resultados["RMSE"],
    MAE = resultados["MAE"],
    R2 = resultados["Rsquared"],
    r = cor(y_real, y_pred)  # Coeficiente de correlación
  )
}

# Crear tabla comparativa
resultados <- bind_rows(
  KNN = calcular_metricas(test$SalePrice, pred_knn),
  Lineal = calcular_metricas(test$SalePrice, pred_lineal),
  Árbol = calcular_metricas(test$SalePrice, pred_arbol),
  NaiveBayes = calcular_metricas(test$SalePrice, pred_naivbayes),
  .id = "Modelo"
)

# Mostrar tabla
print(resultados)

```

Podemos notar que para todas las medidas de error excepto el MAE el mejor modelo es el KNN, el segundo mejor es el modelo lineal, seguido por el Arbol y el peor es el Naïve Bayes. 

# 4. Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta.

```{r Recuperacion de varibale}
train$precio_categoria<-cut(train$SalePrice, 
                            breaks = c(0, 129975, 214000,Inf),
                            labels = c("Economica", "Intermedia", "Cara" ),
                            include.lowest = TRUE)

test$precio_categoria<-cut(test$SalePrice, 
                            breaks = c(0, 129975, 214000, Inf),
                            labels = c("Economica", "Intermedia", "Cara"),
                            include.lowest = TRUE)
#normalizar datos

x_train<-train[, !(names(train) %in% c("SalePrice", "precio_categoria"))]
y_train<-train$precio_categoria

x_test<- test[, !(names(test) %in% c("SalePrice", "precio_categoria"))]
y_test<-test$precio_categoria


#modelo de casificacion 

modelo_knn_class<-train(
  x=x_train,
  y=y_train,
  method="knn"
  )

```


# 5. Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar.

```{r prediccion}
predic_knn_clas<-predict(modelo_knn_class, newdata = x_test)

```

# 6. Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.

```{r matriz de confusion}

consfusion_m<- confusionMatrix(predic_knn_clas, y_test)
print(consfusion_m)

```
El modelo clasificó corectamente el 75.23% de las casas, segun el Accuaracy, es moderado. Hay desbalance de clases, en especifico para la clase Lujo, nótese por la sensibilidad, ya que no identifico a ninguna casa de lujo. La clasificacion erronea de viviendas de lujo como econommicas tienen impacto significativo ya que tienen una gran diferencia en el valor de las propiedades.


# 7.  Analice el modelo. ¿Cree que pueda estar sobreajustado?

```{r}
# analicemos el rendimiento del modelo con los datos de entrenamiento
predic_knn_clas_train<-predict(modelo_knn_class, newdata = x_train)

consfusion_m<- confusionMatrix(predic_knn_clas_train, y_train)
print(consfusion_m)

```
Al hacer una matriz de confucion con los datos de entrenamiento, podelmos notar que clasificó correctamente el 78.91% de las casa, muy similar al rendimiento con los datos de prueba (75.23%) . En general no parece sobre ajustado. Comparemos el rendimiento por clases:



```{r, echo=FALSE}
library(knitr)
library(kableExtra)
library(dplyr)

# Definir los datos
metrics <- c("Sensitivity", "Specificity", "Pos Pred Value", "Neg Pred Value", 
             "Prevalence", "Detection Rate", "Detection Prevalence", "Balanced Accuracy")

data <- data.frame(
  Metric = metrics,
  `Economica (Train)` = c(0.6367, 0.9674, 0.8670, 0.8888, 0.2500, 0.1592, 0.1836, 0.8021),
  `Economica (Test)` = c(0.6239, 0.9694, 0.8718, 0.8855, 0.2500, 0.1560, 0.1789, 0.7966),
  `Intermedia (Train)` = c(0.8755, 0.7176, 0.7576, 0.8512, 0.5020, 0.4395, 0.5801, 0.7966),
  `Intermedia (Test)` = c(0.8539, 0.6498, 0.7110, 0.8150, 0.5023, 0.4289, 0.6032, 0.7518),
  `Cara (Train)` = c(0.7677, 0.9390, 0.8058, 0.9246, 0.2480, 0.1904, 0.2363, 0.8533),
  `Cara (Test)` = c(0.6759, 0.9329, 0.7684, 0.8974, 0.2477, 0.1674, 0.2179, 0.8044)
)

# Mostrar la tabla en formato LaTeX con ajuste de tamaño
kable(data, format = "latex", caption = "Métricas de Test y Train Comparadas") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"))
```

En la tabla podemos notar que las columnas de test son similares a las de train, por lo que no pare que haya sobre ajuste.

# 8. Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor?

```{r}

trctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3)
modelo_knn_class_cruss <- train(
  x= x_train, 
  y=y_train, 
  method = "knn", 
  trControl = trctrl, 
  preProcess= c("center","scale")
)

pred_test_cruss<-predict(modelo_knn_class_cruss, newdata = x_test)

consfusion_m<- confusionMatrix(pred_test_cruss, y_test)
print(consfusion_m)


```

Parece que con validación cruzada el modelo es un poco mejor. porque clasifica muy bien las casas económicas pero un poco peor las demás classes. En general la diferencia no parece significativas. 

#9. Tanto para los modelos de regresión como de clasificación, pruebe con varios valores de los hiperparámetros ¿Qué parámetros pueden tunearse en un KNN?, use el mejor modelo del tuneo, ¿Mejoraron los resultados usando el mejor modelo ahora? Explique
```{r}
trctrl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3)
# Ajuste de k con valores específicos: Clasificacion Por si te sirve
tune_grid <- expand.grid(k = c(3, 5, 7, 9, 11))
modelo_knn_class <- train(
  x = x_train,
  y = y_train,
  method = "knn",
  trControl = trctrl,
  tuneGrid = tune_grid
)

#analis
resultados_knn_class <- modelo_knn_class$results
mejor_k <- modelo_knn_class$bestTune$k

print(resultados_knn_class)

# Predicciones con el mejor modelo KNN en el conjunto de prueba
predicciones_knn_class_mejor <- predict(modelo_knn_class, newdata = x_test)



```

Nótese que el mejor rendimiento de K lo obtuvo k =9 con presicion de 0.734 y con coeficiente Kappa 0.556. Veamos como queda la matiz de confusión con el mejor valor de K.


```{r}
# Matriz de confusión y métricas de rendimiento
matriz_confusion_knn_mejor <- confusionMatrix(predicciones_knn_class_mejor, y_test)

print(matriz_confusion_knn_mejor)
```


El modelo muestra que tiene un rendiemiento del 74% y con coeficiente kappa de 0.5791 lo que se puede interpretar como una concordancia moderada. 

Por parte del informe de sencibilidad, el modelo es bueno identificando las casas clasificadas como intermedio, que por el contrario para las casas económicas que tiene cierta dificultad para clasificarlas.


#10. Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación), el modelo de random forest y el de naive bayes que hizo en las entregas pasadas. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?


```{r}
# Matriz de confusión para KNN
matriz_confusion_knn_mejor <- confusionMatrix(predicciones_knn_class_mejor, y_test)
print("Matriz de confusión KNN:")
print(matriz_confusion_knn_mejor)

# Matriz de confusión para Random Forest
print("Matriz de confusión Random Forest:")
print(confusionMatrix(predictions, test_set$precio_categoria))

# Matriz de confusión para Naive Bayes


train$precio_categoria<-cut(train$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)

test$precio_categoria<-cut(test$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)


#modelo NB para clasificacion

modeloClas<-naiveBayes(precio_categoria~.- SalePrice, data=train)

pred_nb_clas<-predict(modeloClas, newdata=test[, !names(test) %in% c("salePrice", "PriceCateoria") ])
x<-confusionMatrix(pred_nb_clas, test$precio_categoria)

print("Matriz de confusión Naive Bayes:")
print(x)



# Matriz de confusión para Árbol de Decisión de Clasificación

rf_model <- randomForest(precio_categoria ~ ., data = train_set, ntree = 500, importance = TRUE)

predictions <- predict(rf_model, newdata = test_set)

# Genera la matriz de confusión comparando las predicciones con los valores reales

matriz_confusion_arbol <- confusionMatrix(predictions, test_set$precio_categoria)
print("Matriz de confusión Árbol de Decisión de Clasificación:")
print(matriz_confusion_arbol)

```

```{r}
# Datos de los modelos
modelos <- c("KNN", "Random Forest", "Naive Bayes", "Árbol de Decisión")
precision <- c(0.75, 0.9707, 0.4771, 0.9707 )
kappa <- c(0.5874, 0.9562, 0.3121, 0.9562 )
sensibilidad <- c(0.7241, 0.8500, 0.4523, 0.85)
especificidad <- c(0.8533, 0.9902, 0.8293, 0.9902)


tabla_comparativa <- data.frame(
  Modelo = modelos,
  Precision = precision,
  Kappa = kappa,
  Sensibilidad = sensibilidad,
  Especificidad = especificidad
)


print(tabla_comparativa)
```


Random forest es el mejor, por su precision al 97%, el modelo KNN puede ser usado pero puede mejorar, pero Naive Bayes no se recomienda.






















