---
title: "Informe Proyecto 2 entrega 2"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---
```{r, librerías y base de datos,include=FALSE}
library(randomForest)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
library(glmnet)
library(caret) 
datos <- read.csv('train.csv')

vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

datosC <- datos %>%
  select(all_of(vars_cuantitativas))
# completar variables:

datosC$LotFrontage[is.na(datosC$LotFrontage)] <- 0
datosC$MasVnrArea[is.na(datosC$MasVnrArea)] <- 0
datosC$GarageYrBlt[is.na(datosC$GarageYrBlt)] <- median(datosC$GarageYrBlt, na.rm = TRUE)


```


# git: https://github.com/JusSolo/Mineria_Proyecto2.git


# 1 Se usaran los mismos conjuntos de entrenamiento y prueba que usó para los modelos de regresión lineal en la entrega anterior. 
 Pero antes se agregará la varible nueva CategoriaPrecios, que agrupe los precios de las casas en 3 categorías: Económicas, Intermedias o Caras.

```{r, creacion de nueva variable, echo=FALSE}
# Crear una nueva variable categórica basada en los cuantiles de SalePrice
#datosC$CategoriaPrecio <- cut(
#  datosC$SalePrice,
#  breaks = quantile(datosC$SalePrice, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
#  labels = c("Económicas", "Intermedias", "Caras"),
#  include.lowest = TRUE
#)

# Convertir la variable en un factor
#datosC$CategoriaPrecio <- as.factor(datosC$CategoriaPrecio)

# Verificar la distribución
#table(datosC$CategoriaPrecio)

```

```{r, recuperacion de el training y test }
y<- datosC$SalePrice
set.seed(123)
trainI<- createDataPartition(y, p=0.8, list=FALSE)
train<-datosC[trainI, ]
test<-datosC[-trainI, ]
```



```{r, mostrando los datos, echo=FALSE,}
cat("Conjunto de entrenamiento (cantidad de muestras:", nrow(train), ") \n ")
head(train)

cat("Conjunto de prueba (cantidad de muestras:", nrow(test), ") \n ")
head(test)
```



# 2.  Arbol de regresión para predecir el precio de las casas usando todas las variables.

```{r, primer modelo}
arbol1 <- rpart(SalePrice~.,data = train)
rpart.plot(arbol1)
```



# 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo?
```{r prediccion modelo1}
# Calcular las predicciones
predicciones <- predict(arbol1, newdata = test)

# Calcular MSE (Error Cuadrático Medio)
mse <- mean((train$SalePrice - predicciones)^2)

# Calcular MAE (Error Absoluto Medio)
mae <- mean(abs(train$SalePrice - predicciones))

# Mostrar los resultados
cat("MSE:", mse, "\nMAE:", mae)

```

```{r, plot modelo1}


# Graficar los valores originales del conjunto de prueba
plot(test$SalePrice, col = "blue", main = "Predicciones vs valores originales (Test)", 
     xlab = "Índice", ylab = "SalePrice")

# Agregar las predicciones al gráfico
points(predicciones, col = "red")

# Agregar la leyenda
legend("topright", legend = c("Original", "Predicción"), 
       col = c("blue", "red"), pch = 1, cex = 0.8)

```
El model tiene un MAE y un MSE altos, la predicción es muy burda. 

# 4. Haga, al menos, 3 modelos más, cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas?


```{r, modelos con profundidad acotada}


# Modelo original (sin especificar maxdepth, usa el máximo por defecto)
arbol1 <- rpart(SalePrice ~ ., data = train)

# Modelos con diferentes profundidades
arbol2 <- rpart(SalePrice ~ ., data = train, control = rpart.control(maxdepth = 4))
arbol3 <- rpart(SalePrice ~ ., data = train, control = rpart.control(maxdepth = 3))
arbol4 <- rpart(SalePrice ~ ., data = train, control = rpart.control(maxdepth = 2))

# Función para calcular MSE y MAE
calcular_errores <- function(modelo) {
  pred <- predict(modelo, newdata = train)
  mse <- mean((train$SalePrice - pred)^2)
  mae <- mean(abs(train$SalePrice - pred))
  return(c(MSE = mse, MAE = mae))
}

# Calcular errores para cada modelo
errores1 <- calcular_errores(arbol1)
errores2 <- calcular_errores(arbol2)
errores3 <- calcular_errores(arbol3)
errores4 <- calcular_errores(arbol4)

# Mostrar los resultados
resultados <- data.frame(
  Modelo = c("Original (sin maxdepth)", "maxdepth = 4", "maxdepth = 3", "maxdepth = 2"),
  MSE = c(errores1[1], errores2[1], errores3[1], errores4[1]),
  MAE = c(errores1[2], errores2[2], errores3[2], errores4[2])
)

print(resultados)

# Identificar el mejor modelo (menor MSE)
mejor_modelo <- resultados[which.min(resultados$MSE), "Modelo"]
cat("\nEl mejor modelo según el MSE es:", mejor_modelo, "\n")

```
```{r, plot arbol de modelos}
rpart.plot(arbol2, main = "Árbol con maxdepth = 4")
rpart.plot(arbol3, main = "Árbol con maxdepth = 3")
rpart.plot(arbol4, main = "Árbol con maxdepth = 2")

# Resetear la ventana gráfica
par(mfrow = c(1, 1))
```
Como es de esperar a mayor profundidad mayor error

# 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor?

```{r, echo=FALSE}
# Prepara las variables independientes (X) y la dependiente (y)
X <- model.matrix(SalePrice ~ . , data = train)[, -1]  # Matriz sin el intercepto
y <- train$SalePrice


set.seed(123)
modelo_lasso <- cv.glmnet(X, y, alpha = 1)  # alpha = 1 para Lasso

coeficientes <- coef(modelo_lasso, s = "lambda.min")
variables_seleccionadas <- rownames(coeficientes)[coeficientes[, 1] != 0]
variables_seleccionadas <- variables_seleccionadas[-1]  # Excluye el intercepto

variables_seleccionadas <- variables_seleccionadas[variables_seleccionadas %in% colnames(train)]

cat("Variables seleccionadas:", variables_seleccionadas, "\n")
```


```{r, Comparacion del mejor modelo actual (arbol1) con el mejor modelo de la hoja anterior (modelo1) }


# Modelo original (sin especificar maxdepth, usa el máximo por defecto)
arbol1 <- rpart(SalePrice ~ ., data = train)


#modelo de hoja anterior
# Filtra las variables seleccionadas en el data frame
formula <- as.formula(paste("SalePrice ~", paste(variables_seleccionadas, collapse = "+")))
modelo2 <- lm(formula, data = train)
modelo2 <-step(modelo2, direction = "backward")


# Función para calcular MSE y MAE
calcular_errores <- function(modelo) {
  pred <- predict(modelo, newdata = train)
  mse <- mean((train$SalePrice - pred)^2)
  mae <- mean(abs(train$SalePrice - pred))
  return(c(MSE = mse, MAE = mae))
}

# Calcular errores para cada modelo
erroresarbol1 <- calcular_errores(arbol1)
erroresmodelo2 <- calcular_errores(modelo2)


# Mostrar los resultados
resultados <- data.frame(
  Modelo = c("Arbol 1", "Modelo 2" ),
  MSE = c(erroresarbol1[1], erroresmodelo2[1]),
  MAE = c(erroresarbol1[2], erroresmodelo2[2])
)

print(resultados)

# Identificar el mejor modelo (menor MSE)
mejor_modelo <- resultados[which.min(resultados$MSE), "Modelo"]
cat("\nEl mejor modelo según el MSE es:", mejor_modelo, "\n")

```
# 6. Dependiendo del análisis exploratorio elaborado cree una variable respuesta que le permita clasificar las casas en Económicas, Intermedias o Caras. Los límites de estas clases deben tener un fundamento en la distribución de los datos de precios, y estar bien explicados

```{r Distribucion de precios de las casa }
hist(train$SalePrice, main="Distribucion de SalePrice", xlab="Precio de Venta")

boxplot(train$SalePrice, main="Boxplot de SalePrice")
summary(train$SalePrice)
quantile(train$SalePrice, probs=c(0.25, 0.5, 0.75))
```

Notese que en el histograma hay asimetria positiva, por lo que hay cola larga a los precios altos.

En el Boxplot se nota valores atipicos, que son significativamente altos, que pueden conciderarse como las casas con precios muy altos, por lo que se concidera crear otra cateoria, que se llame lujo representado las casas que en precio son superiores a 400000.

La creacion de la variable categorica se basa en los cuartiles de SalePrice, con los cortes lógicos de la siguiente forma:

Económicas, hasta el primer cuartil (129975)
Intermedias, entre el primer y tercer cuartil (129975, 214000)
Cara, por encima del tercer cuartil hasta el comienzo de puntos atipicos (214000, 400000)
Lujo, Por encima de los valores atipicos (400000)

La distribución queda de la siguente forma.

```{r creacion de variable categorica}
train$precio_categoria<-cut(train$SalePrice, 
                            breaks = c(0, 129975, 214000, 400000, Inf),
                            labels = c("Economica", "Intermedia", "Cara", "Lujo"),
                            include.lowest = TRUE)
table(train$precio_categoria)

```

# 7. Elabore un árbol de clasificación utilizando la variable respuesta que creó en el punto anterior. Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las casas, no incluya el precio de venta para entrenar el modelo.


```{r arbol de clasificacion}
arbol_clasificacion<- rpart(precio_categoria ~ .-SalePrice, data = train )
#summary(arbol_clasificacion)
```


```{r train y test con nueva variable}
set.seed(123)
corte<-sample(1:nrow(train), 0.8 * nrow(train))
train_set<-train[corte, ]
test_set<-train[-corte, ]
train$SalePrice<-NULL
test$SalePrice<-NULL

``` 

```{r modelo1_class}
rpart.plot(arbol_clasificacion, type = 4, extra=1)
```

El árbol utiliza las varibales GrLivArea, OverallQual, BsmtFinSF1, YearBuilt, para clasificar las viviendas. Mostrando que el tamaño, calidad y antiguedad de la casa son los factores que mas influyen en el precio. Las viviendas de precio alto son las de alta calidad y gran área. Las de baja calidad y area mas pequeña las calasifica como en precio bajo. La clasificacion de Lujo tiene menor cantidad de de valores de acierto, que puede deberse a pocos datos en esta categoria a comparacion con las otras. 



# 8. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.

# 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.

```{r prediccion del modelo}
predicciones_clas<-predict(arbol_clasificacion, newdata = test_set)


predicciones_clas <-apply(predicciones_clas, 1, function(x) colnames(predicciones_clas)[which.max(x)])

predicciones_clas<- as.factor(predicciones_clas)

cfm <- confusionMatrix(predicciones_clas, test_set$precio_categoria)
print(cfm)
```

Según la matriz de confusión el modelo clasifica de buena manera las categorias económica y Lujo con precision alta, aunque hay cierta confusión entre las categorias intermedia y cara, donde se clasifica algunas casas en intermedia cuando es cara y viceversa. 

Las categorias muestran alta sencibilidad y y especificidad por lo que el modelo identifica correctamente las viviendas en cada categoría. POr otro lado la categoria Intermedia tiene el valor mas alto de 0.9892 a comparación con Lujo que tiene 0.8000, por que se concluye que el modelo tiende a clasificar de mejor manera la categoria Intermedia que Lujo a comparación con intermedia.

Nótese que como valor de Accuracy hay 88.89%, por lo que el modelo tiene buen rendimiento.

# 10. Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior?
```{r Modelo de validacion cruzada }


control<-trainControl(method = "cv", number = 10)
abrol_cv<-train(precio_categoria ~ .- SalePrice, data=train_set, method="rpart", trControl=control)
predicciones_cv<-predict(abrol_cv, newdata=test_set)
accuarcy_cv<-sum(diag(table(test_set$precio_categoria, predicciones_cv))) /nrow(test_set)
print(paste("Precision con validacion cruzada:", accuarcy_cv))


predicciones_test<-predict(arbol_clasificacion, newdata=test_set, type = "class")
accuarcy_test<-sum(diag(table(test_set$precio_categoria, predicciones_cv))) /nrow(test_set)
print(paste("Precision del modelo original:", accuarcy_test))

diferencia<-accuarcy_cv-accuarcy_test

result<-sign(diferencia)

print(paste("Diferencia de precision:", diferencia))

```

Los modelos tiene el mismmo rendimiento 

# 11. Haga al menos, 3 modelos más, cambiando la profundidad del árbol. ¿Cuál funcionó mejor?

```{r}
arbol_clasificacion1 <- rpart(precio_categoria ~ ., data = train,control = rpart.control(maxdepth = 6) )
arbol_clasificacion2 <- rpart(precio_categoria ~ ., data = train,control = rpart.control(maxdepth = 3) )
arbol_clasificacion3 <- rpart(precio_categoria ~ ., data = train,control = rpart.control(maxdepth = 2) )

rpart.plot(arbol_clasificacion1, type = 4, extra=1)
rpart.plot(arbol_clasificacion2, type = 4, extra=1)
rpart.plot(arbol_clasificacion3, type = 4, extra=1)




```

```{r}

errores2 <- calcular_errores(arbol_clasificacion1)
errores3 <- calcular_errores(arbol_clasificacion2)
errores4 <- calcular_errores(arbol_clasificacion3)


# Generar predicciones para el conjunto de prueba

pred1 <- predict(arbol_clasificacion1, newdata = test_set, type = "class")
pred2 <- predict(arbol_clasificacion2, newdata = test_set, type = "class")
pred3 <- predict(arbol_clasificacion3, newdata = test_set, type = "class")

# Crear matrices de confusión
confusion1 <- confusionMatrix(pred1, test_set$precio_categoria)
confusion2 <- confusionMatrix(pred2, test_set$precio_categoria)
confusion3 <- confusionMatrix(pred3, test_set$precio_categoria)


# Mostrar las matrices de confusión
print("Matriz de Confusión para arbol_clasificacion1:")
print(confusion1)

print("Matriz de Confusión para arbol_clasificacion2:")
print(confusion2)

print("Matriz de Confusión para arbol_clasificacion3:")
print(confusion3)

```
Como es de esperarce el Arbol que tienen mayor profundidad, de 6 de profundidad fue el que obtuvo mejores resultados. Sin embargo tiene una presicion de 83.76% lo que podría indicar que el modelo empieza a sobre ajustarce. Como el modelo de profundidad 3 tiene la midad de profundidad y una precicion de  0.7863% la cual es parecida con menos riesgo de sobre ajuste y con un modelo más simple. Por ello se considera al arbo de profundidad 3 como el mejor modelo para la clasificacion. 


# 12. Repita los análisis usando random forest como algoritmo de predicción, explique sus
resultados comparando ambos algoritmos.

```{r}
rf_model <- randomForest(precio_categoria ~ ., data = train_set, ntree = 500, importance = TRUE)
# Suponiendo que ya has creado el modelo rf_model




# Suponiendo que ya has creado el modelo rf_model
plot(rf_model, main = "Error de OOB")
# Suponiendo que ya has creado el modelo rf_model
varImpPlot(rf_model, main = "Importancia de Variables")


# Realiza las predicciones sobre test_set
predictions <- predict(rf_model, newdata = test_set)

# Genera la matriz de confusión comparando las predicciones con los valores reales
confusion_matrix <- table(Predicted = predictions, Actual = test_set$precio_categoria)
print(confusion_matrix)

# Opcional: Calcula la precisión del modelo
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Precisión:", round(accuracy * 100, 2), "%"))


```

