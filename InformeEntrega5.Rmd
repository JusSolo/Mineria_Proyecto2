---
title: "Informe Proyecto 2 entrega 5"
author:
- "Juan Luis Solórzano (carnet: 201598)"
- "Micaela Yataz (carnet: 18960)"
date: "2025-01-20"
output: pdf_document
---

https://github.com/JusSolo/Mineria_Proyecto2.git 


```{r, include=FALSE}
# Cargar librerías necesarias
library(randomForest)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
library(glmnet)
library(e1071)
library(Metrics)
library(tidyverse)
library(class)



# Cargar la base de datos
datos <- read.csv('train.csv')

# Definir variables cuantitativas
vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

# Imputar valores faltantes en variables específicas
datos <- datos %>%
  mutate(
    LotFrontage = ifelse(is.na(LotFrontage), 0, LotFrontage),
    MasVnrArea = ifelse(is.na(MasVnrArea), 0, MasVnrArea),
    GarageYrBlt = ifelse(is.na(GarageYrBlt), median(GarageYrBlt, na.rm = TRUE), GarageYrBlt)
  )

# Seleccionar solo variables cuantitativas
datosC <- datos[, vars_cuantitativas]
```

# git: https://github.com/JusSolo/Mineria_Proyecto2.git



```{r, include=FALSE}
# Cargar librerías necesarias
library(randomForest)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
library(glmnet)
library(e1071)
library(Metrics)
library(tidyverse)
library(class)
library(corrplot)



# Cargar la base de datos
datos <- read.csv('train.csv')

# Definir variables cuantitativas
vars_cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", 
                        "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", 
                        "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", 
                        "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", 
                        "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", 
                        "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", 
                        "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold")

# Imputar valores faltantes en variables específicas
datos <- datos %>%
  mutate(
    LotFrontage = ifelse(is.na(LotFrontage), 0, LotFrontage),
    MasVnrArea = ifelse(is.na(MasVnrArea), 0, MasVnrArea),
    GarageYrBlt = ifelse(is.na(GarageYrBlt), median(GarageYrBlt, na.rm = TRUE), GarageYrBlt)
  )

# Seleccionar solo variables cuantitativas
datosC <- datos[, vars_cuantitativas]
```


# git: https://github.com/JusSolo/Mineria_Proyecto2.git

#1. Cree una variable dicotómica por cada una de las categorías de la variable respuesta categórica que creó en hojas anteriores. Debería tener 3 variables dicotómicas (valores 0 y 1) una que diga si la vivienda es cara o no, media o no, económica o no.

```{r, recuperacion de el training y test }
y<- datos$SalePrice
set.seed(123)
trainI<- createDataPartition(y, p=0.7, list=FALSE)

train<-datos[trainI, ]
test<-datos[-trainI, ]

```

```{r Recuperacion de varibale}
train$precio_categoria<-cut(train$SalePrice, 
                            breaks = c(0, 129975, 214000,Inf),
                            labels = c("Economica", "Intermedia", "Cara" ),
                            include.lowest = TRUE)

test$precio_categoria<-cut(test$SalePrice, 
                            breaks = c(0, 129975, 214000, Inf),
                            labels = c("Economica", "Intermedia", "Cara"),
                            include.lowest = TRUE)


```


```{r creacion de variable dicotomica en train y test}
train$casa_cara<-ifelse(train$precio_categoria=="Cara",1,0)
train$casa_intermedia<-ifelse(train$precio_categoria=="Intermedio",1,0)
train$casa_economica<-ifelse(train$precio_categoria=="Economica",1,0)

test$casa_cara<-ifelse(test$precio_categoria=="Cara",1,0)
test$casa_intermedia<-ifelse(test$precio_categoria=="Intermedio",1,0)
test$casa_economica<-ifelse(test$precio_categoria=="Economica",1,0)

head(train[, c("precio_categoria", "casa_cara", "casa_intermedia", "casa_economica")])
head(test[,c("precio_categoria", "casa_cara", "casa_intermedia", "casa_economica")])
```


#2. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las hojas anteriores.
```{r}

x_train<-train[, !(names(train) %in% c("SalePrice", "precio_categoria"))]
y_train<-train$precio_categoria

x_test<- test[, !(names(test) %in% c("SalePrice", "precio_categoria"))]
y_test<-test$precio_categoria
```

#3. Elabore un modelo de regresión logística para conocer si una vivienda es cara o no, utilizando el conjunto de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código. Use validación cruzada.


```{r}
ybin<-train$casa_cara
x_vars<-train[,vars_cuantitativas]

modelo<-cbind(casa_cara=ybin,x_vars)

modelo_logistico<-glm(casa_cara~.,data = modelo, family = binomial)
summary(modelo_logistico)


```
Los coeficientes de las varibales son muy grandes lo que puede haber multicolinealidad.  El AIC de este modelo es 1151.3
```{r}
control<-trainControl(method = "cv", number = 5)

modelo_cv<- train(as.factor(casa_cara) ~.,
                  data = modelo, 
                  method ="glm", 
                  family = binomial(),
                  trContol=control)
                  
print(modelo_cv)
```
Hay problema de multicolinealidad entre las variables predictorias.


#4. Analice el modelo. Determine si hay multicolinealidad en las variables, y cuáles son las que aportan al modelo, por su valor de significación. Haga un análisis de correlación de las variables del modelo y especifique si el modelo se adapta bien a los datos.

```{r correlacion y multicolinealidad}
correl<-cor(x_vars, use = "complete.obs")
corrplot(correl, method = "color", tl.cex = 0.6)
```
Las variables con correlacion fuerte son SalePrice, OveralQual y GrLivArea son posiblemente los predictores mas importantes del precio de las casas. Pero por la multicolinealidad, sera necesario seleccionar una variable.

#5. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.
```{r}

x_test<-test[,vars_cuantitativas]
pred<-predict(modelo_logistico, newdata = x_test, type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(factor(prediccion), factor(test$casa_cara), positive="1")
```

El modelo aunque parece que tiene buen rendimiento predictivo, es importante ver la multicolinealidad para obtener otro modelo mas estable.

#6. Explique si hay sobreajuste (overfitting) o no (recuerde usar para esto los errores del conjunto de prueba y de entrenamiento). Muestre las curvas de aprendizaje usando los errores de los conjuntos de entrenamiento y prueba


```{r}
library(Metrics)
tamaños<-seq(0.1,1,by=0.1)
errores_train<-c()
errores_test<-c()

for (t in tamaños) {
  idx <- sample(1:nrow(modelo), size = floor(t * nrow(modelo)))
  sub_train <- modelo[idx, ]
  sub_model <- glm(casa_cara ~ ., data = sub_train, family = binomial)

  pred_train <- ifelse(predict(sub_model, newdata = sub_train, type = "response") > 0.5, 1, 0)
  pred_test <- ifelse(predict(sub_model, newdata = x_test, type = "response") > 0.5, 1, 0)

  errores_train <- c(errores_train, mean(pred_train != sub_train$casa_cara))
  errores_test <- c(errores_test, mean(pred_test != test$casa_cara))
}

# Graficar errores
plot(tamaños, errores_train, type = "o", col = "blue", ylim = c(0,1),
     ylab = "Error", xlab = "Proporción del conjunto de entrenamiento",
     main = "Curvas de aprendizaje")
lines(tamaños, errores_test, type = "o", col = "red")
legend("topright", legend = c("Entrenamiento", "Prueba"),
       col = c("blue", "red"), lty = 1)


```
Segun la grafica el modelo tienen muy poco error en el conjunto de entrenamiento y prueba, por lo que se ajusta bien.


